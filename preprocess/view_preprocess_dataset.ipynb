{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d47059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from timm.models.vision_transformer import PatchEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = np.fromfile('./preprocess/000000.bin', dtype=np.float32).reshape(-1, 9) # 9 channels: x, y, z, intensity, flag, R, G, B, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_ori = np.fromfile('./000000.bin', dtype=np.float32).reshape(-1, 4) # 9 channels: x, y, z, intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Projection\n",
    "class ScanProjection(object):\n",
    "    '''\n",
    "    Project the 3D point cloud to 2D data with range projection\n",
    "\n",
    "    Adapted from A. Milioto et al. https://github.com/PRBonn/lidar-bonnetal\n",
    "    '''\n",
    "\n",
    "    def __init__(self, proj_w, proj_h):\n",
    "        # params of proj img size\n",
    "        self.proj_w = proj_w\n",
    "        self.proj_h = proj_h\n",
    "\n",
    "\n",
    "    def doProjection(self, pointcloud: np.ndarray):\n",
    "\n",
    "        # get depth of all points\n",
    "        depth = np.linalg.norm(pointcloud[:, :3], 2, axis=1)\n",
    "        # get point cloud components\n",
    "        x = pointcloud[:, 0]\n",
    "        y = pointcloud[:, 1]\n",
    "        z = pointcloud[:, 2]\n",
    "        # label is the last column of pointcloud\n",
    "        label = pointcloud[:,-1]\n",
    "        # remove the last column from pointcloud\n",
    "        pointcloud = pointcloud[:, :-1]\n",
    "        # remove flag, R, G, and B from pointcloud\n",
    "        # pointcloud = pointcloud[:, :-4]  # now only has [x, y, z, intensity]\n",
    "        # get angles of all points\n",
    "        yaw = -np.arctan2(y, -x)\n",
    "        proj_x = 0.5 * (yaw / np.pi + 1.0)  # in [0.0, 1.0]\n",
    "        #breakpoint()\n",
    "        new_raw = np.nonzero((proj_x[1:] < 0.2) * (proj_x[:-1] > 0.8))[0] + 1\n",
    "        proj_y = np.zeros_like(proj_x)\n",
    "        proj_y[new_raw] = 1\n",
    "        proj_y = np.cumsum(proj_y)\n",
    "        # scale to image size using angular resolution\n",
    "        proj_x = proj_x * self.proj_w - 0.001\n",
    "\n",
    "        # round and clamp for use as index\n",
    "        proj_x = np.maximum(np.minimum(\n",
    "            self.proj_w - 1, np.floor(proj_x)), 0).astype(np.int32)\n",
    "        # wrap proj_x so if proj_x < 1024 it will be added 1024, if proj_x >= 1024 it will be subtracted 1024\n",
    "        proj_x = np.where(proj_x < 1024, proj_x + 1024, proj_x - 1024)\n",
    "        proj_y = np.maximum(np.minimum(\n",
    "            self.proj_h - 1, np.floor(proj_y)), 0).astype(np.int32)\n",
    "\n",
    "        # order in decreasing depth\n",
    "        indices = np.arange(depth.shape[0])\n",
    "        order = np.argsort(depth)[::-1]\n",
    "        depth = depth[order]\n",
    "        indices = indices[order]\n",
    "        pointcloud = pointcloud[order]\n",
    "        proj_y = proj_y[order]\n",
    "        proj_x = proj_x[order]\n",
    "        label = label[order]\n",
    "\n",
    "        # get projection result\n",
    "        proj_range = np.full((self.proj_h, self.proj_w), -1, dtype=np.float32)\n",
    "        proj_range[proj_y, proj_x] = depth\n",
    "\n",
    "        proj_pointcloud = np.full((self.proj_h, self.proj_w, pointcloud.shape[1]), -1, dtype=np.float32)\n",
    "        proj_pointcloud[proj_y, proj_x] = pointcloud\n",
    "\n",
    "        proj_idx = np.full((self.proj_h, self.proj_w), -1, dtype=np.int32)\n",
    "        proj_idx[proj_y, proj_x] = indices\n",
    "\n",
    "        proj_label = np.full((self.proj_h, self.proj_w), 0, dtype=np.int32)\n",
    "        proj_label[proj_y, proj_x] = label\n",
    "\n",
    "        # create proj_tensor with cascade proj_pointcloud and proj_range\n",
    "        # proj_pointcloud has size (64, 2048, 4)\n",
    "        # proj_range has size (64, 2048)\n",
    "        # print(f'proj_range_shape:{proj_range.shape}, proj_pointcloud_shape: {proj_pointcloud.shape}, proj_label_shape: {proj_label.shape}')\n",
    "        proj_pointcloud = proj_pointcloud[0:48, 790:1250, :]  # cut the pointcloud to [H, W, C]\n",
    "        proj_range =proj_range[0:48, 790:1250]  # cut the range to [H, W]\n",
    "        proj_label = proj_label[0:48, 790:1250]\n",
    "        # img = img[:, :, 0:48, 790:1250]  # cut the image to [C, H, W]\n",
    "        # label = label[:, 0:48, 790:1250]  # cut the label to [H, W]\n",
    "\n",
    "        proj_tensor = np.concatenate((proj_range[..., np.newaxis], proj_pointcloud), axis=-1) # [range, x, y, z, flag, R, G, B]\n",
    "        return proj_tensor, proj_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7772be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DataLoader\n",
    "class KITTISegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, sequences):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = []\n",
    "        for seq in sequences:\n",
    "            seq_dir = os.path.join(root_dir, seq)\n",
    "            assert os.path.exists(seq_dir), f\"Sequence {seq} does not exist in {root_dir}\"\n",
    "            file_list = []\n",
    "            pc_dir = os.path.join(seq_dir, 'preprocess')\n",
    "            # Get the list of files (full path) in the point cloud directory\n",
    "            file_list = [os.path.join(pc_dir, f) for f in os.listdir(pc_dir) if f.endswith('.bin')]\n",
    "            self.file_list.extend(file_list)\n",
    "        # Setup the projection parameters\n",
    "        self.projection = ScanProjection(proj_w=2048, proj_h=64)\n",
    "        # Define the learning map for semantic labels\n",
    "        # This map is used to convert the original labels to a smaller set of classes\n",
    "        self.learning_map = {0: 0, 1: 0, 10: 1, 11: 2, 13: 5, 15: 3, 16: 5, 18: 4, 20: 5,\n",
    "            30: 6, 31: 7, 32: 8, 40: 9, 44: 10, 48: 11, 49: 12, 50: 13,\n",
    "            51: 14, 52: 0, 60: 9, 70: 15, 71: 16, 72: 17, 80: 18, 81: 19,\n",
    "            99: 0, 252: 1, 253: 7, 254: 6, 255: 8, 256: 5, 257: 5, 258: 4, 259: 5}\n",
    "        # Create a mapping array with size large enough to cover the largest key\n",
    "        self.max_key = max(self.learning_map.keys())\n",
    "        self.map_array = np.zeros((self.max_key + 1,), dtype=np.int32)\n",
    "        # Fill the mapping array with the learning map values\n",
    "        for key, value in self.learning_map.items():\n",
    "            self.map_array[key] = value\n",
    "            \n",
    "    # Read the point cloud data from binary files\n",
    "    @staticmethod\n",
    "    def readPCD(path):\n",
    "        pcd = np.fromfile(path, dtype=np.float32).reshape(-1, 9) # 9 channels: x, y, z, intensity, flag, R, G, B, label\n",
    "        return pcd\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pc_path = self.file_list[idx]\n",
    "\n",
    "        # Load binary data\n",
    "        pc = self.readPCD(pc_path)  # x, y, z, intensity\n",
    "        img, label = self.projection.doProjection(pc) # shape [H, W, C]\n",
    "        # Map the labels using the learning map\n",
    "        label = self.map_array[label]  # map to smaller set of classes\n",
    "        img = torch.tensor(img).permute(2, 0, 1).float()  # to [C, H, W]\n",
    "        label = torch.tensor(label).long()                # [H, W]\n",
    "        # Normalize the tensor\n",
    "        # mean = torch.tensor([12.12, 10.88, 0.23, -1.04, 0.21])\n",
    "        # std = torch.tensor([12.32, 11.47, 6.91, 0.86, 0.16])\n",
    "        # img = (img - mean[:, None, None]) / std[:, None, None]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0688c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = KITTISegmentationDataset('../SemanticKITTI/dataset/sequences',['08'])\n",
    "loader_val = DataLoader(dataset_val, batch_size=1, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# get a sample from the dataset and plot it\n",
    "for img, label in loader_val:\n",
    "    print(img.shape, label.shape)\n",
    "    # cut and center image so that x: 790->1250; y: 0-> 48\n",
    "\n",
    "    print(img.shape, label.shape)\n",
    "    # plot the first image, assume that the first channel is range, the last 3 channels are R, G, B\n",
    "    proj_range = img[0, 0].numpy()  # get the range channel\n",
    "    proj_rgb = img[0, 6:9].numpy()   # get the RGB channels\n",
    "    # save the RGB image to a file\n",
    "    proj_rgb = (proj_rgb * 255).astype(np.uint8)  # convert to uint8\n",
    "    proj_rgb = proj_rgb.transpose(1, 2, 0)\n",
    "    imwrite = plt.imsave('proj_rgb.png', proj_rgb)\n",
    "    print(proj_range.shape, proj_rgb.shape)\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(16, 2))\n",
    "    # no axis and make it bigger\n",
    "    axs[0].axis('off')\n",
    "    axs[0].imshow(proj_range, cmap='jet')\n",
    "    axs[1].axis('off')\n",
    "    axs[1].imshow(proj_rgb)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykitti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
