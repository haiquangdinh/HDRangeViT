{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aefcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad1dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# either using it from the colorize module or using it directly\n",
    "# from colorize.colorize import doColorize\n",
    "\n",
    "# This applied to semanticKITTI dataset only\n",
    "def load_calib(calib_file):\n",
    "    calib = {}\n",
    "    with open(calib_file) as f:\n",
    "        for line in f:\n",
    "            key, *vals = line.strip().split()\n",
    "            calib[key] = np.array(vals, dtype=np.float32).reshape(-1)\n",
    "    return calib\n",
    "\n",
    "def doColorize(pc_file, im_file, calib_file, cam: int = 0):\n",
    "    # 1. Load point cloud\n",
    "    points = np.fromfile(pc_file, dtype=np.float32).reshape(-1, 4) # (x, y, z, intensity)\n",
    "    pts_velo = points[:, :3] # (x, y, z)\n",
    "    # 2. Load image\n",
    "    img = cv2.imread(im_file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = img.shape\n",
    "    # 3. Load calibration\n",
    "    calib = load_calib(calib_file)\n",
    "    if cam == 0:\n",
    "        P = calib['P2:'].reshape(3, 4) # Left camera proj\n",
    "    elif cam == 1:\n",
    "        P = calib['P3:'].reshape(3, 4) # right camera proj\n",
    "    Tr = calib['Tr:'].reshape(3, 4) # LiDAR to cam0\n",
    "    # 4. Transform LiDAR points to camera frame\n",
    "    pts_hom = np.hstack((pts_velo, np.ones((pts_velo.shape[0], 1))))  # N×4\n",
    "    pts_cam = ((Tr @ pts_hom.T).reshape(3, -1)).T  # N×3 \n",
    "    # 5. Project to image plane\n",
    "    pts_img = (P @ np.hstack((pts_cam, np.ones((pts_cam.shape[0], 1)))).T).T\n",
    "    pts_img[:, 0] /= pts_img[:, 2]\n",
    "    pts_img[:, 1] /= pts_img[:, 2]\n",
    "    # 6. Filter valid points\n",
    "    valid = (pts_cam[:, 2] > 0) & \\\n",
    "            (pts_img[:, 0] >= 0) & (pts_img[:, 0] < w) & \\\n",
    "            (pts_img[:, 1] >= 0) & (pts_img[:, 1] < h)\n",
    "    pts_valid = pts_velo[valid]\n",
    "    uv = pts_img[valid, :2].astype(int)\n",
    "    colors = img[uv[:, 1], uv[:, 0]] / 255.0  # RGB normalized\n",
    "    # 7. Print number of valid points along with number of points\n",
    "    # print(f'Number of valid points/ Number of points: {np.sum(valid)}/{pts_velo.shape[0]} ({np.sum(valid)/pts_velo.shape[0]*100:.2f}%)')\n",
    "    # 8. Cascade the valid array to points\n",
    "    points_add = np.concatenate((points, np.zeros((points.shape[0], 4))), axis=1)\n",
    "    points_add[:, 4] = valid.astype(np.int32)  # Assign 1 if valid, 0 otherwise \n",
    "    points_add[valid, 5:8] = colors  # RGB\n",
    "    # points_add is the original point cloud with additional columns for valid flag and RGB colors (x,y,z,intensity,flag,r,g,b)\n",
    "    # check if points_add meet the expected dimention\n",
    "    assert points_add.shape[1] == 8, f\"Expected points_add to have 8 columns, but got {points_add.shape[1]}\"\n",
    "    # pts_valid is the (x, y, z) of the valid points\n",
    "    # colors is the RGB values of the valid points\n",
    "\n",
    "    return points_add, pts_valid, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd997d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# either using it from projection module or using it directly\n",
    "\n",
    "# This applied to semanticKITTI dataset only\n",
    "proj_w=2048\n",
    "proj_h=64\n",
    "def doProjection(pointcloud: np.ndarray, wrap_around: int = 0):\n",
    "    # get depth of all points\n",
    "    depth = np.linalg.norm(pointcloud[:, :3], 2, axis=1)\n",
    "    # get point cloud components\n",
    "    x = pointcloud[:, 0]\n",
    "    y = pointcloud[:, 1]\n",
    "\n",
    "    # get angles of all points\n",
    "    yaw = -np.arctan2(y, -x)\n",
    "    proj_x = 0.5 * (yaw / np.pi + 1.0)  # in [0.0, 1.0]\n",
    "    new_raw = np.nonzero((proj_x[1:] < 0.2) * (proj_x[:-1] > 0.8))[0] + 1\n",
    "    proj_y = np.zeros_like(proj_x)\n",
    "    proj_y[new_raw] = 1\n",
    "    proj_y = np.cumsum(proj_y)\n",
    "    # scale to image size using angular resolution\n",
    "    proj_x = proj_x * proj_w - 0.001\n",
    "    # --- Wrap around vertical axis if specified ---\n",
    "    if wrap_around > 0 and wrap_around < proj_w:\n",
    "        # Shift proj_x so that wrap_around is the new \"zero\"\n",
    "        proj_x = (proj_x - wrap_around) % proj_w\n",
    "        \n",
    "    # print(f'proj_y: [{proj_y.min()} - {proj_y.max()}] - ({(proj_y < self.proj_h).astype(np.int32).sum()} - {(proj_y >= self.proj_h).astype(np.int32).sum()})')\n",
    "\n",
    "    # round and clamp for use as index\n",
    "    proj_x = np.maximum(np.minimum(\n",
    "        proj_w - 1, np.floor(proj_x)), 0).astype(np.int32)\n",
    "\n",
    "    proj_y = np.maximum(np.minimum(\n",
    "        proj_h - 1, np.floor(proj_y)), 0).astype(np.int32)\n",
    "\n",
    "    # order in decreasing depth\n",
    "    indices = np.arange(depth.shape[0])\n",
    "    order = np.argsort(depth)[::-1]\n",
    "    depth = depth[order]\n",
    "    indices = indices[order]\n",
    "    pointcloud = pointcloud[order]\n",
    "    proj_y = proj_y[order]\n",
    "    proj_x = proj_x[order]\n",
    "\n",
    "    # get projection result\n",
    "    proj_range = np.full((proj_h, proj_w), -1, dtype=np.float32)\n",
    "    proj_range[proj_y, proj_x] = depth\n",
    "\n",
    "    proj_pointcloud = np.full((proj_h, proj_w, pointcloud.shape[1]), -1, dtype=np.float32)\n",
    "    proj_pointcloud[proj_y, proj_x] = pointcloud\n",
    "\n",
    "    # Concatenate proj_range as the first channel\n",
    "    proj_range_expanded = proj_range[..., np.newaxis]  # shape (proj_h, proj_w, 1)\n",
    "    proj_pointcloud = np.concatenate([proj_range_expanded, proj_pointcloud], axis=-1)\n",
    "\n",
    "    # proj_idx = np.full((proj_h, proj_w), -1, dtype=np.int32)\n",
    "    # proj_idx[proj_y, proj_x] = indices\n",
    "    # proj_mask = (proj_idx > 0).astype(np.int32)\n",
    "\n",
    "    # proj_pointcloud is the 2D numpy array with dimention (proj_h, proj_w, 10) and each elements include range,x,y,z,intensity,flag,r,g,b,label\n",
    "    # check if proj_pointcloud meet the expected dimention\n",
    "    assert proj_pointcloud.shape[2] == 10, f\"Expected proj_pointcloud to have 10 channels, but got {proj_pointcloud.shape[2]}\"\n",
    "\n",
    "    return proj_pointcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the label data from files\n",
    "@staticmethod\n",
    "def readLabel(path):\n",
    "    label = np.fromfile(path, dtype=np.int32)\n",
    "    orig_sem_label = label & 0xFFFF  # semantic label in lower half\n",
    "    # Define the learning map for semantic labels\n",
    "    # This map is used to convert the original labels to a smaller set of classes\n",
    "    learning_map = {0: 0, 1: 0, 10: 1, 11: 2, 13: 5, 15: 3, 16: 5, 18: 4, 20: 5,\n",
    "        30: 6, 31: 7, 32: 8, 40: 9, 44: 10, 48: 11, 49: 12, 50: 13,\n",
    "        51: 14, 52: 0, 60: 9, 70: 15, 71: 16, 72: 17, 80: 18, 81: 19,\n",
    "        99: 0, 252: 1, 253: 7, 254: 6, 255: 8, 256: 5, 257: 5, 258: 4, 259: 5}\n",
    "    # Convert orig_sem_label to sem_label using the map\n",
    "    sem_label = np.vectorize(learning_map.get)(orig_sem_label)\n",
    "    return sem_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_rootdir = '..\\\\..\\\\sequences'\n",
    "sequences = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in tqdm(sequences, desc=\"Processing Sequences\"):\n",
    "    basedir = os.path.join(sequences_rootdir, seq)\n",
    "    pointdir = os.path.join(sequences_rootdir, seq, 'velodyne')\n",
    "    labeldir = os.path.join(basedir, 'labels')\n",
    "    imgdir = os.path.join(basedir, 'image_2')\n",
    "    calib_file = os.path.join(basedir, 'calib.txt')\n",
    "    # search all .bin files in pointdir and put them in a list\n",
    "    point_files = sorted([f for f in os.listdir(pointdir) if f.endswith('.bin')])\n",
    "    # search all .png files in imgdir and put them in a list\n",
    "    img_files = sorted([f for f in os.listdir(imgdir) if f.endswith('.png')])\n",
    "    # search all .label files in labeldir and put them in a list\n",
    "    label_files = sorted([f for f in os.listdir(labeldir) if f.endswith('.label')])\n",
    "    # make sure the number of point files and image files match\n",
    "    if len(point_files) != len(img_files):\n",
    "        raise ValueError(\"Number of point files and image files do not match.\")\n",
    "    if len(point_files) != len(label_files):\n",
    "        raise ValueError(\"Number of point files and label files do not match.\")\n",
    "\n",
    "    # save the preprocess point cloud to a new file in the subfolder 'preprocess', use the same filename\n",
    "    preprocess_dir = os.path.join(basedir, 'preprocess')\n",
    "    os.makedirs(preprocess_dir, exist_ok=True)\n",
    "\n",
    "    # go through the list of point files and image files and colorize the points\n",
    "    for point_file, img_file, label_file in tqdm(zip(point_files, img_files, label_files), total=len(point_files), desc=\"Colorizing point clouds\", leave=False):\n",
    "        pc_file = os.path.join(pointdir, point_file) \n",
    "        im_file = os.path.join(imgdir, img_file)\n",
    "        label_file = os.path.join(labeldir, label_file)\n",
    "        # print out the files involved\n",
    "        # print(f\"Processing {pc_file}, {im_file}, {label_file}\")\n",
    "        label = readLabel(label_file)  # N x 1\n",
    "        points, pts_valid, colors = doColorize(pc_file, im_file, calib_file)\n",
    "        # check if length of points and labels match\n",
    "        if len(points) != len(label):\n",
    "            raise ValueError(f\"Number of points ({len(points)}) does not match number of labels ({len(label)}) in file {label_file}.\")\n",
    "        # cascade the labels to the points\n",
    "        points_output = np.hstack((points, label[:, np.newaxis]))  # add labels\n",
    "        # do the scan projection\n",
    "        points_final = doProjection(points_output, wrap_around=1024)\n",
    "        # save the points to a new file in the preprocess directory\n",
    "        output_file = os.path.join(preprocess_dir, point_file)\n",
    "        points_final.astype(np.float32).tofile(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykitti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
