{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eae6c79",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'waymo_open_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwaymo_open_dataset\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m range_image_utils\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'waymo_open_dataset'"
     ]
    }
   ],
   "source": [
    "#  This tutorial show that only pandas is used\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory with all components\n",
    "dataset_dir = '../WoD/validation'\n",
    "\n",
    "context_name = '17065833287841703_2980_000_3000_000'\n",
    "\n",
    "def read(tag: str) -> pd:\n",
    "  \"\"\"Creates a Dask DataFrame for the component specified by its tag.\"\"\"\n",
    "  paths = f'{dataset_dir}/{tag}/{context_name}.parquet'\n",
    "  return pd.read_parquet(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAYMO_TO_SEMKITTI_20 = {\n",
    "    0: 0,   # UNKNOWN -> unlabeled\n",
    "    1: 1,   # CAR -> car\n",
    "    2: 4,   # TRUCK -> truck\n",
    "    3: 4,   # BUS -> truck\n",
    "    4: 5,   # OTHER_VEHICLE -> other-vehicle\n",
    "    5: 8,   # MOTORCYCLIST -> motorcyclist\n",
    "    6: 7,   # BICYCLIST -> bicyclist\n",
    "    7: 6,   # PEDESTRIAN -> person\n",
    "    8: 19,  # SIGN -> traffic-sign\n",
    "    9: 19,  # TRAFFIC_LIGHT -> traffic-sign\n",
    "    10: 18, # POLE -> pole\n",
    "    11: 18, # CONSTRUCTION_CONE -> pole (approx)\n",
    "    12: 2,  # BICYCLE -> bicycle\n",
    "    13: 3,  # MOTORCYCLE -> motorcycle\n",
    "    14: 13, # BUILDING -> building\n",
    "    15: 15, # VEGETATION -> vegetation\n",
    "    16: 16, # TREE_TRUNK -> trunk\n",
    "    17: 12, # CURB -> other-ground (alt: road=9)\n",
    "    18: 9,  # ROAD -> road\n",
    "    19: 9,  # LANE_MARKER -> road\n",
    "    20: 12, # OTHER_GROUND -> other-ground\n",
    "    21: 11, # WALKABLE -> sidewalk\n",
    "    22: 11, # SIDEWALK -> sidewalk\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf91ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _sample_rgb_nearest(img, rows, cols):\n",
    "    h, w = img.shape[:2]\n",
    "    rows = np.clip(rows, 0, h - 1)\n",
    "    cols = np.clip(cols, 0, w - 1)\n",
    "    return img[rows, cols, :]\n",
    "\n",
    "def colorize_range_image_v2(\n",
    "    proj,                 # [H, W, 6] = [cam1,row1,col1, cam2,row2,col2]\n",
    "    camera_images,        # dict: {camera_id:int -> np.uint8 [Hc,Wc,3]}\n",
    "    default_color=(128,128,128)\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      colors_hw3: uint8 [H, W, 3]\n",
    "      used_mask:  bool  [H, W]  (True where a camera projection was used)\n",
    "    \"\"\"\n",
    "    H, W, C = proj.shape\n",
    "    assert C == 6, \"Expected v2 projection with two triplets: [cam1,row1,col1, cam2,row2,col2]\"\n",
    "    colors = np.empty((H, W, 3), dtype=np.uint8)\n",
    "    colors[:] = np.array(default_color, dtype=np.uint8)\n",
    "    used = np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    cam1 = proj[..., 0]; r1 = proj[..., 1]; c1 = proj[..., 2]\n",
    "    cam2 = proj[..., 3]; r2 = proj[..., 4]; c2 = proj[..., 5]\n",
    "    # SWAP row and col here!\n",
    "    r1, c1 = c1, r1\n",
    "    r2, c2 = c2, r2\n",
    "    # Pass 1: try primary projection per camera\n",
    "    for cid, img in camera_images.items():\n",
    "        m1 = (cam1 == cid)\n",
    "        if not np.any(m1):\n",
    "            continue\n",
    "        rr = r1[m1].astype(np.int32)\n",
    "        cc = c1[m1].astype(np.int32)\n",
    "        rgb = _sample_rgb_nearest(img, rr, cc)\n",
    "        ii, jj = np.nonzero(m1)\n",
    "        colors[ii, jj, :] = rgb\n",
    "        used[ii, jj] = True\n",
    "\n",
    "    # Pass 2: fallback to secondary where primary failed\n",
    "    need = ~used\n",
    "    for cid, img in camera_images.items():\n",
    "        m2 = (cam2 == cid) & need\n",
    "        if not np.any(m2):\n",
    "            continue\n",
    "        rr = r2[m2].astype(np.int32)\n",
    "        cc = c2[m2].astype(np.int32)\n",
    "        rgb = _sample_rgb_nearest(img, rr, cc)\n",
    "        ii, jj = np.nonzero(m2)\n",
    "        colors[ii, jj, :] = rgb\n",
    "        used[ii, jj] = True\n",
    "\n",
    "    return colors, used\n",
    "\n",
    "def flatten_colors_for_points(used_mask, colors_hw3):\n",
    "    \"\"\"\n",
    "    Align colors with flattened valid LiDAR pixels (same mask you'd use for ranges>0, etc.)\n",
    "    Returns:\n",
    "      colors_n3: uint8 [N, 3]\n",
    "      idx_n2:    int   [N, 2]  (row, col) indices in the range image\n",
    "    \"\"\"\n",
    "    ii, jj = np.nonzero(used_mask)\n",
    "    return colors_hw3[ii, jj, :], np.stack([ii, jj], axis=1)\n",
    "\n",
    "def decode_jpeg_image(img_proto):\n",
    "    \"\"\"Decode a Waymo camera image proto into uint8 HxWx3 (RGB).\"\"\"\n",
    "    img = tf.image.decode_jpeg(img_proto, channels=3)\n",
    "    return img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b64eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_segmentation = read('lidar_segmentation')  # about 30 frames with label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d67609",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_segmentation_first_frame = lidar_segmentation.iloc[0]\n",
    "#  get the key.frame_timestamp_micros of this first frame\n",
    "timestamp = lidar_segmentation_first_frame['key.frame_timestamp_micros']\n",
    "# from now on, raw data, camera and label will be filtered by this timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbdc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "label_channel = lidar_segmentation_first_frame['[LiDARSegmentationLabelComponent].range_image_return1.values']\n",
    "label_channel = label_channel.reshape(64, 2650, 2) # instance ID and semantic ID\n",
    "lb1 = label_channel[:,:,1] # semantic ID: from 0 to 22\n",
    "# Convert orig_sem_label to sem_label using the map\n",
    "sem_label = np.vectorize(WAYMO_TO_SEMKITTI_20.get)(lb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_df = read('lidar')\n",
    "# filter lidar_df that only has key.laser_name == 1 (first lidar) and key.frame_timestamp_micros == timestamp\n",
    "lidar_df = lidar_df[lidar_df['key.laser_name'] == 1]\n",
    "lidar_df = lidar_df[lidar_df['key.frame_timestamp_micros'] == timestamp]\n",
    "# raw lidar data\n",
    "lidar_raw = lidar_df.iloc[0]['[LiDARComponent].range_image_return1.values']\n",
    "lidar_raw = lidar_raw.reshape(64, 2650, 4)    # range, intensity, elongation, is_in_no_label_zone\n",
    "# remove elongation and is_in_no_label_zone\n",
    "lidar_range = lidar_raw[:,:,0]\n",
    "point_range = lidar_raw[:,:,0] \n",
    "point_intensity = lidar_raw[:,:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae880f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib = read('lidar_calibration')\n",
    "calib = calib[calib['key.laser_name'] == 1]\n",
    "extrinsic = calib.iloc[0]['[LiDARCalibrationComponent].extrinsic.transform'].reshape(4, 4)\n",
    "beam_inclination = calib.iloc[0]['[LiDARCalibrationComponent].beam_inclination.values']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b363a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lidar_range, extrinsic, and beam_inclination to tensors with [B, W, H] with B=1\n",
    "lidar_range = tf.convert_to_tensor(lidar_range, dtype=tf.float32)\n",
    "lidar_range = tf.expand_dims(lidar_range, axis=0)\n",
    "extrinsic = tf.convert_to_tensor(extrinsic, dtype=tf.float32)\n",
    "extrinsic = tf.expand_dims(extrinsic, axis=0)\n",
    "beam_inclination = tf.convert_to_tensor(beam_inclination, dtype=tf.float32)\n",
    "beam_inclination = tf.expand_dims(beam_inclination, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 3D points (vehicle frame)\n",
    "points = range_image_utils.extract_point_cloud_from_range_image(\n",
    "    lidar_range,\n",
    "    extrinsic,\n",
    "    beam_inclination\n",
    ")\n",
    "#  make point to by numarray\n",
    "\n",
    "points_np = points.numpy()\n",
    "# squeeze to remove dimensions of size 1\n",
    "points_np = points_np.squeeze()\n",
    "# sanity check points_np: if point_range = -1, then points_np = -1\n",
    "points_np[point_range == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c78cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  put the range image so that it has size {H, W} with five channel: range, x, y, z, intensity in such order\n",
    "# lidar_raw[:,:,0] then points_np then lidar_raw[:,:,1]\n",
    "points_final = np.zeros((64, 2650, 5))\n",
    "points_final[:,:,0] = point_range\n",
    "points_final[:,:,1:4] = points_np\n",
    "points_final[:,:,4] = point_intensity\n",
    "# now we have data that similar to that of the paper. Just need to add R,G, B (which is huge thing to do)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb9f25",
   "metadata": {},
   "source": [
    "### Colorized point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cam_img_df = read('camera_image')\n",
    "lidar_camera_projection_df = read('lidar_camera_projection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566de57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter using timestamp and key.laser_name\n",
    "lidar_camera_projection_df = lidar_camera_projection_df[lidar_camera_projection_df['key.frame_timestamp_micros'] == timestamp]\n",
    "lidar_camera_projection_df = lidar_camera_projection_df[lidar_camera_projection_df['key.laser_name'] == 1]\n",
    "cam_img_df = cam_img_df[cam_img_df['key.frame_timestamp_micros'] == timestamp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c186f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each row in cam_img_df, decode the image with [CameraImageComponent].image and key.camera_name (not that camera ID = key.camera_name - 1)\n",
    "cam_images = {}\n",
    "for index, row in cam_img_df.iterrows():\n",
    "    cam_images[row['key.camera_name']] = decode_jpeg_image(row['[CameraImageComponent].image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the [LiDARCameraProjectionComponent].range_image_return1.values\n",
    "projection_df = lidar_camera_projection_df.iloc[0]['[LiDARCameraProjectionComponent].range_image_return1.values'].reshape(64, 2650,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rgb_grid, used_mask = colorize_range_image_v2(projection_df, cam_images, default_color=(0,0,0))\n",
    "pc_colors_n3, idx_n2 = flatten_colors_for_points(used_mask, rgb_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598adb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the final points with range, x, y, z, intensity, flag, R, G, B and label\n",
    "# flag is valid when and only when range > 0 and used_mask is one\n",
    "points_final_output = np.zeros((64, 2650, 10))\n",
    "points_final_output[:,:,0] = points_final[:,:,0]  # range\n",
    "points_final_output[:,:,1] = points_final[:,:,1]  # x\n",
    "points_final_output[:,:,2] = points_final[:,:,2]  # y\n",
    "points_final_output[:,:,3] = points_final[:,:,3]  # z\n",
    "points_final_output[:,:,4] = points_final[:,:,4]  # intensity\n",
    "points_final_output[:,:,5] = (points_final[:,:,0] > 0) & (used_mask)  # flag\n",
    "points_final_output[:,:,6] = rgb_grid[:,:, 0]  # R\n",
    "points_final_output[:,:,7] = rgb_grid[:,:, 1]  # G\n",
    "points_final_output[:,:,8] = rgb_grid[:,:, 2]  # B\n",
    "points_final_output[:,:,9] = sem_label  # label (not used)\n",
    "\n",
    "# sanity put: any -1 element is set to 0\n",
    "points_final_output[points_final_output == -1] = 0\n",
    "points_final_output.astype(np.float32).tofile(\"output_file.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
