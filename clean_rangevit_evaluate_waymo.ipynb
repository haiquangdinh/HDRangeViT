{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c379e83a",
   "metadata": {},
   "source": [
    "# <span style=\"color:red; font-weight:bold; \">A clean and modern RangeViT implementation for Waymo</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b73372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from model.WaymoSegmentationDataset import WaymoSegmentationDataset\n",
    "from model.RangeViTSegmentationModel import RangeViTSegmentationModel\n",
    "\n",
    "from segmentation_models_pytorch.losses import FocalLoss, LovaszLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace32aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "val_dataset = WaymoSegmentationDataset('../WoD/validation', training=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f224fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torchmetrics or do manually\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "# create a metric and put it on gpu\n",
    "metric = MulticlassJaccardIndex(num_classes=20, average=None, ignore_index=0).to(device)\n",
    "\n",
    "num_classes = 20\n",
    "in_channels = 9 # range, x, y, z, intensity, flag, R, G, B\n",
    "num_epochs = 60\n",
    "model = RangeViTSegmentationModel(n_classes=num_classes, in_channels=in_channels).to(device)\n",
    "# criterion = LovaszLoss(mode='multiclass', ignore_index=0, per_image=False)\n",
    "focal = FocalLoss(mode='multiclass', ignore_index=0)\n",
    "lovasz = LovaszLoss(mode='multiclass', ignore_index=0, per_image=False)\n",
    "def criterion(outputs, targets):\n",
    "    return focal(outputs, targets) + lovasz(outputs, targets)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec6f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, loader, criterion, metric):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metric.reset()  # Reset the IoU metric for the evaluation\n",
    "    with torch.no_grad():\n",
    "        batch_bar = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "        for imgs, labels in batch_bar:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            metric.update(preds, labels)\n",
    "            ious = metric.compute()\n",
    "            mean_iou = torch.mean(ious[ious != 0])\n",
    "            batch_bar.set_postfix(loss=loss.item(), mIoU=mean_iou.item())\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Evaluation Loss: {total_loss/len(loader):.4f}, mIoU: {mean_iou.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a87603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model if you have a pre-trained one\n",
    "pretrain_path = 'range_vit_segmentation4645.pth'\n",
    "if os.path.exists(pretrain_path):\n",
    "    print(f\"Loading pre-trained model from {pretrain_path}\")\n",
    "    model.load_state_dict(torch.load('range_vit_segmentation.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b18f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71e70df74dd43ee8e3f80de76a95b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 7.8585, mIoU: 0.0249\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, val_loader, criterion, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykitti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
