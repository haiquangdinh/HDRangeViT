{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c379e83a",
   "metadata": {},
   "source": [
    "# <span style=\"color:red; font-weight:bold; \">A clean and modern RangeViT implementation for SemanticKITTI in PyTorch 2.4</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e44a8",
   "metadata": {},
   "source": [
    "## <span style=\"font-weight:bold\">1. DataLoader</span>\n",
    "\n",
    "### 1.1 Dataset Structure\n",
    "The dataset should be structured as follows:\n",
    "```\n",
    "sequences/\n",
    "├── 00/\n",
    "│   ├── preprocess/\n",
    "│   │   ├── 000000.bin\n",
    "│   │   ├── 000001.bin\n",
    "├── 01/\n",
    "│   ├── preprocess/\n",
    "│   │   ├── 000000.bin\n",
    "│   │   ├── 000001.bin\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from model.KITTISegmentationDataset import KITTISegmentationDataset\n",
    "from model.RangeViTSegmentationModel import RangeViTSegmentationModel\n",
    "\n",
    "from segmentation_models_pytorch.losses import FocalLoss, LovaszLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace32aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# dataset = KITTISegmentationDataset('../sequences',['03'], training=True)\n",
    "dataset = KITTISegmentationDataset('../sequences',['00', '01', '02', '03', '04', '05', '06', '07', '09', '10'], training=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = KITTISegmentationDataset('../sequences',['08'], training=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torchmetrics or do manually\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "# create a metric and put it on gpu\n",
    "metric = MulticlassJaccardIndex(num_classes=20, average=None, ignore_index=0).to(device)\n",
    "\n",
    "num_classes = 20\n",
    "in_channels = 9 # range, x, y, z, intensity, flag, R, G, B\n",
    "num_epochs = 60\n",
    "model = RangeViTSegmentationModel(n_classes=num_classes, in_channels=in_channels).to(device)\n",
    "# criterion = LovaszLoss(mode='multiclass', ignore_index=0, per_image=False)\n",
    "focal = FocalLoss(mode='multiclass', ignore_index=0)\n",
    "lovasz = LovaszLoss(mode='multiclass', ignore_index=0, per_image=False)\n",
    "def criterion(outputs, targets):\n",
    "    return focal(outputs, targets) + lovasz(outputs, targets)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, metric,epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    metric.reset()  # Reset the IoU metric for the next epoch\n",
    "    batch_bar = tqdm(loader, desc=f\"Training Epoch {epoch+1}\", leave=False)\n",
    "    for imgs, labels in batch_bar:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        metric.update(preds, labels)\n",
    "        ious = metric.compute()\n",
    "        mean_iou = torch.mean(ious[ious != 0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_bar.set_postfix(loss=loss.item(), mIoU=mean_iou.item())\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}] Loss: {total_loss/len(loader):.4f}, mIoU: {mean_iou.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, loader, criterion, metric):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metric.reset()  # Reset the IoU metric for the evaluation\n",
    "    with torch.no_grad():\n",
    "        batch_bar = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "        for imgs, labels in batch_bar:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            metric.update(preds, labels)\n",
    "            ious = metric.compute()\n",
    "            mean_iou = torch.mean(ious[ious != 0])\n",
    "            batch_bar.set_postfix(loss=loss.item(), mIoU=mean_iou.item())\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Evaluation Loss: {total_loss/len(loader):.4f}, mIoU: {mean_iou.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a87603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model if you have a pre-trained one\n",
    "pretrain_path = 'range_vit_segmentation.pth'\n",
    "if os.path.exists(pretrain_path):\n",
    "    print(f\"Loading pre-trained model from {pretrain_path}\")\n",
    "    model.load_state_dict(torch.load('range_vit_segmentation.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model\n",
    "best_val_mIoU = 0.0\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    train_one_epoch(model, loader, optimizer, criterion, metric,epoch)\n",
    "    if epoch % 5 == 0: # Evaluate every 5 epochs\n",
    "        eval_model(model, val_loader, criterion, metric)\n",
    "        ious = metric.compute()\n",
    "        current_val_mIoU = torch.mean(ious[ious != 0]).item()\n",
    "        if current_val_mIoU > best_val_mIoU:\n",
    "            best_val_mIoU = current_val_mIoU\n",
    "            torch.save(model.state_dict(), 'range_vit_segmentation.pth')\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy weights when two models doesn't have exact same architecture\n",
    "# old_dict = torch.load('range_vit_segmentation_4616.pth')\n",
    "# from model.model_utils import approximately_clone_state_dict\n",
    "# new_dict = approximately_clone_state_dict(model.state_dict(), old_dict)\n",
    "# model.load_state_dict(new_dict)\n",
    "# torch.save(model.state_dict(), 'range_vit_segmentation.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "eval_model(model, val_loader, criterion, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation with the best model\n",
    "# model = RangeViTSegmentationModel(n_classes=num_classes, in_channels=in_channels).to(device)\n",
    "# model.load_state_dict(torch.load('range_vit_segmentation.pth'))\n",
    "# eval_model(model, val_loader, criterion, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd90b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'range_vit_segmentation.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce574fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print structure of model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear cuda memory\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykitti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
