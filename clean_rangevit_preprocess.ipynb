{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c379e83a",
   "metadata": {},
   "source": [
    "# <span style=\"color:red; font-weight:bold; \">A clean and modern RangeViT implementation for SemanticKITTI in PyTorch 2.4</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e44a8",
   "metadata": {},
   "source": [
    "## <span style=\"font-weight:bold\">1. DataLoader</span>\n",
    "\n",
    "### 1.1 Dataset Structure\n",
    "The dataset should be structured as follows:\n",
    "```\n",
    "sequences/\n",
    "├── 00/\n",
    "│   ├── preprocess/\n",
    "│   │   ├── 000000.bin\n",
    "│   │   ├── 000001.bin\n",
    "├── 01/\n",
    "│   ├── preprocess/\n",
    "│   │   ├── 000000.bin\n",
    "│   │   ├── 000001.bin\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from model.KITTISegmentationDataset import KITTISegmentationDataset\n",
    "from model.RangeViTSegmentationModel import RangeViTSegmentationModel\n",
    "\n",
    "from segmentation_models_pytorch.losses import FocalLoss, LovaszLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace32aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = KITTISegmentationDataset('../sequences',['00', '01', '02', '03', '04', '05', '06', '07', '09', '10'], training=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = KITTISegmentationDataset('../sequences',['08'], training=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torchmetrics or do manually\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "# create a metric and put it on gpu\n",
    "metric = MulticlassJaccardIndex(num_classes=20, average=None, ignore_index=0).to(device)\n",
    "\n",
    "num_classes = 20\n",
    "in_channels = 9 # range, x, y, z, intensity, flag, R, G, B\n",
    "num_epochs = 60\n",
    "model = RangeViTSegmentationModel(n_classes=num_classes, in_channels=in_channels).to(device)\n",
    "# criterion = LovaszLoss(mode='multiclass', ignore_index=0, per_image=False)\n",
    "focal = FocalLoss(mode='multiclass', ignore_index=0)\n",
    "lovasz = LovaszLoss(mode='multiclass', ignore_index=0, per_image=False)\n",
    "def criterion(outputs, targets):\n",
    "    return focal(outputs, targets) + lovasz(outputs, targets)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, metric,epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    metric.reset()  # Reset the IoU metric for the next epoch\n",
    "    batch_bar = tqdm(loader, desc=f\"Training Epoch {epoch+1}\", leave=False)\n",
    "    for imgs, labels in batch_bar:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        metric.update(preds, labels)\n",
    "        ious = metric.compute()\n",
    "        mean_iou = torch.mean(ious[ious != 0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_bar.set_postfix(loss=loss.item(), mIoU=mean_iou.item())\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}] Loss: {total_loss/len(loader):.4f}, mIoU: {mean_iou.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, loader, criterion, metric):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metric.reset()  # Reset the IoU metric for the evaluation\n",
    "    with torch.no_grad():\n",
    "        batch_bar = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "        for imgs, labels in batch_bar:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            metric.update(preds, labels)\n",
    "            ious = metric.compute()\n",
    "            mean_iou = torch.mean(ious[ious != 0])\n",
    "            batch_bar.set_postfix(loss=loss.item(), mIoU=mean_iou.item())\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Evaluation Loss: {total_loss/len(loader):.4f}, mIoU: {mean_iou.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model\n",
    "# Load the model if you have a pre-trained one\n",
    "pretrain_path = 'range_vit_segmentation.pth'\n",
    "if os.path.exists(pretrain_path):\n",
    "    print(f\"Loading pre-trained model from {pretrain_path}\")\n",
    "    model.load_state_dict(torch.load('range_vit_segmentation.pth'))\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    train_one_epoch(model, loader, optimizer, criterion, metric,epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        eval_model(model, val_loader, criterion, metric)\n",
    "    scheduler.step()\n",
    "    if (epoch == 0):\n",
    "        ious = metric.compute()\n",
    "        best_val_mIoU = torch.mean(ious[ious != 0])\n",
    "    else:\n",
    "        ious = metric.compute()\n",
    "        current_val_mIoU = torch.mean(ious[ious != 0]).item()\n",
    "        if current_val_mIoU > best_val_mIoU:\n",
    "            best_val_mIoU = current_val_mIoU\n",
    "            torch.save(model.state_dict(), 'range_vit_segmentation.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5961a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain_path = 'range_vit_segmentation.pth'\n",
    "# torch.save(model.state_dict(), pretrain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation with the best model\n",
    "model.load_state_dict(torch.load('range_vit_segmentation.pth'))\n",
    "model.eval()\n",
    "metric.reset()  # Reset the IoU metric for validation\n",
    "with torch.no_grad():\n",
    "    for images, targets in val_loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        metric.update(outputs, targets)\n",
    "    ious = metric.compute()\n",
    "    val_mIoU = torch.mean(ious[ious != 0]).item()\n",
    "    print(f\"Validation mIoU: {val_mIoU:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce574fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print structure of model\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe69402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear gpu memory\n",
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykitti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
