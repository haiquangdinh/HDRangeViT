{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c379e83a",
   "metadata": {},
   "source": [
    "# <span style=\"color:red; font-weight:bold; \">A clean and modern RangeViT implementation for SemanticKITTI in PyTorch 2.4</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e44a8",
   "metadata": {},
   "source": [
    "## <span style=\"font-weight:bold\">1. DataLoader</span>\n",
    "\n",
    "### 1.1 Dataset Structure\n",
    "The dataset should be structured as follows:\n",
    "```\n",
    "sequences/\n",
    "├── 00/\n",
    "│   ├── preprocess/\n",
    "│   │   ├── 000000.bin\n",
    "│   │   ├── 000001.bin\n",
    "├── 01/\n",
    "│   ├── preprocess/\n",
    "│   │   ├── 000000.bin\n",
    "│   │   ├── 000001.bin\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from model.KITTISegmentationDataset import KITTISegmentationDataset\n",
    "from model.RangeViTSegmentationModel import RangeViTSegmentationModel\n",
    "\n",
    "from segmentation_models_pytorch.losses import FocalLoss, LovaszLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace32aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = KITTISegmentationDataset('../sequences',['00', '01', '02', '03', '04', '05', '06', '07', '09', '10'], training=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = KITTISegmentationDataset('../sequences',['08'], training=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torchmetrics or do manually\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "# create a metric and put it on gpu\n",
    "metric = MulticlassJaccardIndex(num_classes=20, average=None, ignore_index=0).to(device)\n",
    "\n",
    "num_classes = 20\n",
    "in_channels = 9 # range, x, y, z, intensity, flag, R, G, B\n",
    "num_epochs = 60\n",
    "model = RangeViTSegmentationModel(n_classes=num_classes, in_channels=in_channels).to(device)\n",
    "# criterion = LovaszLoss(mode='multiclass', ignore_index=0, per_image=False)\n",
    "focal = FocalLoss(mode='multiclass', ignore_index=0)\n",
    "lovasz = LovaszLoss(mode='multiclass', ignore_index=0, per_image=False)\n",
    "def criterion(outputs, targets):\n",
    "    return focal(outputs, targets) + lovasz(outputs, targets)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, metric,epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    metric.reset()  # Reset the IoU metric for the next epoch\n",
    "    batch_bar = tqdm(loader, desc=f\"Training Epoch {epoch+1}\", leave=False)\n",
    "    for imgs, labels in batch_bar:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        metric.update(preds, labels)\n",
    "        ious = metric.compute()\n",
    "        mean_iou = torch.mean(ious[ious != 0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_bar.set_postfix(loss=loss.item(), mIoU=mean_iou.item())\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}] Loss: {total_loss/len(loader):.4f}, mIoU: {mean_iou.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, loader, criterion, metric):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metric.reset()  # Reset the IoU metric for the evaluation\n",
    "    with torch.no_grad():\n",
    "        batch_bar = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "        for imgs, labels in batch_bar:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            metric.update(preds, labels)\n",
    "            ious = metric.compute()\n",
    "            mean_iou = torch.mean(ious[ious != 0])\n",
    "            batch_bar.set_postfix(loss=loss.item(), mIoU=mean_iou.item())\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Evaluation Loss: {total_loss/len(loader):.4f}, mIoU: {mean_iou.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a87603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model if you have a pre-trained one\n",
    "pretrain_path = 'range_vit_segmentation.pth'\n",
    "if os.path.exists(pretrain_path):\n",
    "    print(f\"Loading pre-trained model from {pretrain_path}\")\n",
    "    model.load_state_dict(torch.load('range_vit_segmentation.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze multi-head attention layers, fine-tune LayerNorm and MLP layers in ViT encoder\n",
    "for name, module in model.backbone.named_modules():\n",
    "    # Freeze all MultiheadAttention layers\n",
    "    if isinstance(module, torch.nn.modules.activation.MultiheadAttention) or 'attn' in name:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "    # Unfreeze LayerNorm and MLP layers\n",
    "    if isinstance(module, torch.nn.LayerNorm) or 'mlp' in name:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model\n",
    "best_val_mIoU = 0.0\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    train_one_epoch(model, loader, optimizer, criterion, metric,epoch)\n",
    "    if epoch % 5 == 0: # Evaluate every 5 epochs\n",
    "        eval_model(model, val_loader, criterion, metric)\n",
    "        ious = metric.compute()\n",
    "        current_val_mIoU = torch.mean(ious[ious != 0]).item()\n",
    "        if current_val_mIoU > best_val_mIoU:\n",
    "            best_val_mIoU = current_val_mIoU\n",
    "            torch.save(model.state_dict(), 'range_vit_segmentation.pth')\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation with the best model\n",
    "model = RangeViTSegmentationModel(n_classes=num_classes, in_channels=in_channels).to(device)\n",
    "model.load_state_dict(torch.load('range_vit_segmentation.pth'))\n",
    "eval_model(model, val_loader, criterion, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce574fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print structure of model\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe69402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "model.rangevit.encoder.cls_token\n",
      "model.rangevit.encoder.pos_embed\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.conv1.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.conv1.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.conv2.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.conv2.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn1.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn1.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn1.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn1.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn1.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.conv3.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.conv3.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn2.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn2.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn2.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn2.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.0.bn2.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.conv1.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.conv1.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.conv2.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.conv2.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn1.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn1.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn1.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn1.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn1.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.conv3.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.conv3.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn2.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn2.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn2.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn2.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.1.bn2.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.conv1.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.conv1.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.conv2.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.conv2.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn1.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn1.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn1.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn1.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn1.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.conv3.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.conv3.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn2.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn2.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn2.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn2.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.2.bn2.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv1.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv1.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv2.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv2.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn1.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn1.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn1.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn1.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn1.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv3.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv3.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn2.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn2.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn2.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn2.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn2.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv4.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv4.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn3.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn3.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn3.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn3.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn3.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv5.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.conv5.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn4.weight\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn4.bias\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn4.running_mean\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn4.running_var\n",
      "model.rangevit.encoder.patch_embed.conv_block.3.bn4.num_batches_tracked\n",
      "model.rangevit.encoder.patch_embed.proj_block.1.weight\n",
      "model.rangevit.encoder.patch_embed.proj_block.1.bias\n",
      "model.rangevit.encoder.blocks.0.norm1.weight\n",
      "model.rangevit.encoder.blocks.0.norm1.bias\n",
      "model.rangevit.encoder.blocks.0.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.0.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.0.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.0.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.0.norm2.weight\n",
      "model.rangevit.encoder.blocks.0.norm2.bias\n",
      "model.rangevit.encoder.blocks.0.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.0.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.0.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.0.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.1.norm1.weight\n",
      "model.rangevit.encoder.blocks.1.norm1.bias\n",
      "model.rangevit.encoder.blocks.1.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.1.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.1.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.1.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.1.norm2.weight\n",
      "model.rangevit.encoder.blocks.1.norm2.bias\n",
      "model.rangevit.encoder.blocks.1.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.1.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.1.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.1.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.2.norm1.weight\n",
      "model.rangevit.encoder.blocks.2.norm1.bias\n",
      "model.rangevit.encoder.blocks.2.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.2.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.2.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.2.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.2.norm2.weight\n",
      "model.rangevit.encoder.blocks.2.norm2.bias\n",
      "model.rangevit.encoder.blocks.2.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.2.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.2.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.2.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.3.norm1.weight\n",
      "model.rangevit.encoder.blocks.3.norm1.bias\n",
      "model.rangevit.encoder.blocks.3.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.3.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.3.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.3.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.3.norm2.weight\n",
      "model.rangevit.encoder.blocks.3.norm2.bias\n",
      "model.rangevit.encoder.blocks.3.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.3.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.3.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.3.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.4.norm1.weight\n",
      "model.rangevit.encoder.blocks.4.norm1.bias\n",
      "model.rangevit.encoder.blocks.4.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.4.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.4.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.4.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.4.norm2.weight\n",
      "model.rangevit.encoder.blocks.4.norm2.bias\n",
      "model.rangevit.encoder.blocks.4.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.4.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.4.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.4.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.5.norm1.weight\n",
      "model.rangevit.encoder.blocks.5.norm1.bias\n",
      "model.rangevit.encoder.blocks.5.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.5.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.5.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.5.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.5.norm2.weight\n",
      "model.rangevit.encoder.blocks.5.norm2.bias\n",
      "model.rangevit.encoder.blocks.5.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.5.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.5.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.5.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.6.norm1.weight\n",
      "model.rangevit.encoder.blocks.6.norm1.bias\n",
      "model.rangevit.encoder.blocks.6.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.6.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.6.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.6.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.6.norm2.weight\n",
      "model.rangevit.encoder.blocks.6.norm2.bias\n",
      "model.rangevit.encoder.blocks.6.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.6.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.6.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.6.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.7.norm1.weight\n",
      "model.rangevit.encoder.blocks.7.norm1.bias\n",
      "model.rangevit.encoder.blocks.7.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.7.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.7.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.7.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.7.norm2.weight\n",
      "model.rangevit.encoder.blocks.7.norm2.bias\n",
      "model.rangevit.encoder.blocks.7.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.7.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.7.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.7.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.8.norm1.weight\n",
      "model.rangevit.encoder.blocks.8.norm1.bias\n",
      "model.rangevit.encoder.blocks.8.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.8.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.8.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.8.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.8.norm2.weight\n",
      "model.rangevit.encoder.blocks.8.norm2.bias\n",
      "model.rangevit.encoder.blocks.8.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.8.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.8.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.8.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.9.norm1.weight\n",
      "model.rangevit.encoder.blocks.9.norm1.bias\n",
      "model.rangevit.encoder.blocks.9.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.9.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.9.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.9.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.9.norm2.weight\n",
      "model.rangevit.encoder.blocks.9.norm2.bias\n",
      "model.rangevit.encoder.blocks.9.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.9.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.9.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.9.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.10.norm1.weight\n",
      "model.rangevit.encoder.blocks.10.norm1.bias\n",
      "model.rangevit.encoder.blocks.10.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.10.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.10.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.10.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.10.norm2.weight\n",
      "model.rangevit.encoder.blocks.10.norm2.bias\n",
      "model.rangevit.encoder.blocks.10.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.10.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.10.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.10.mlp.fc2.bias\n",
      "model.rangevit.encoder.blocks.11.norm1.weight\n",
      "model.rangevit.encoder.blocks.11.norm1.bias\n",
      "model.rangevit.encoder.blocks.11.attn.qkv.weight\n",
      "model.rangevit.encoder.blocks.11.attn.qkv.bias\n",
      "model.rangevit.encoder.blocks.11.attn.proj.weight\n",
      "model.rangevit.encoder.blocks.11.attn.proj.bias\n",
      "model.rangevit.encoder.blocks.11.norm2.weight\n",
      "model.rangevit.encoder.blocks.11.norm2.bias\n",
      "model.rangevit.encoder.blocks.11.mlp.fc1.weight\n",
      "model.rangevit.encoder.blocks.11.mlp.fc1.bias\n",
      "model.rangevit.encoder.blocks.11.mlp.fc2.weight\n",
      "model.rangevit.encoder.blocks.11.mlp.fc2.bias\n",
      "model.rangevit.encoder.norm.weight\n",
      "model.rangevit.encoder.norm.bias\n",
      "model.rangevit.decoder.up_conv_block.conv_upsample.0.weight\n",
      "model.rangevit.decoder.up_conv_block.conv_upsample.0.bias\n",
      "model.rangevit.decoder.up_conv_block.conv1.0.weight\n",
      "model.rangevit.decoder.up_conv_block.conv1.0.bias\n",
      "model.rangevit.decoder.up_conv_block.conv1.2.weight\n",
      "model.rangevit.decoder.up_conv_block.conv1.2.bias\n",
      "model.rangevit.decoder.up_conv_block.conv1.2.running_mean\n",
      "model.rangevit.decoder.up_conv_block.conv1.2.running_var\n",
      "model.rangevit.decoder.up_conv_block.conv1.2.num_batches_tracked\n",
      "model.rangevit.decoder.up_conv_block.conv_output.0.weight\n",
      "model.rangevit.decoder.up_conv_block.conv_output.0.bias\n",
      "model.rangevit.decoder.up_conv_block.conv_output.2.weight\n",
      "model.rangevit.decoder.up_conv_block.conv_output.2.bias\n",
      "model.rangevit.decoder.up_conv_block.conv_output.2.running_mean\n",
      "model.rangevit.decoder.up_conv_block.conv_output.2.running_var\n",
      "model.rangevit.decoder.up_conv_block.conv_output.2.num_batches_tracked\n",
      "model.rangevit.kpclassifier.kpconv.weights\n",
      "model.rangevit.kpclassifier.kpconv.kernel_points\n",
      "model.rangevit.kpclassifier.bn.weight\n",
      "model.rangevit.kpclassifier.bn.bias\n",
      "model.rangevit.kpclassifier.bn.running_mean\n",
      "model.rangevit.kpclassifier.bn.running_var\n",
      "model.rangevit.kpclassifier.bn.num_batches_tracked\n",
      "model.rangevit.kpclassifier.head.weight\n",
      "model.rangevit.kpclassifier.head.bias\n",
      "epoch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(\"../model_skitti_trainval_cs_init_h256.pth\", map_location=\"cpu\")\n",
    "if isinstance(state_dict, dict) and \"state_dict\" in state_dict:\n",
    "    state_dict = state_dict[\"state_dict\"]\n",
    "\n",
    "def print_keys(d, prefix=\"\"):\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(prefix + str(k))\n",
    "            print_keys(v, prefix + str(k) + \".\")\n",
    "\n",
    "print_keys(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d9c819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.cls_token\n",
      "backbone.pos_embed\n",
      "backbone.patch_embed.proj.weight\n",
      "backbone.patch_embed.proj.bias\n",
      "backbone.blocks.0.norm1.weight\n",
      "backbone.blocks.0.norm1.bias\n",
      "backbone.blocks.0.attn.qkv.weight\n",
      "backbone.blocks.0.attn.qkv.bias\n",
      "backbone.blocks.0.attn.proj.weight\n",
      "backbone.blocks.0.attn.proj.bias\n",
      "backbone.blocks.0.norm2.weight\n",
      "backbone.blocks.0.norm2.bias\n",
      "backbone.blocks.0.mlp.fc1.weight\n",
      "backbone.blocks.0.mlp.fc1.bias\n",
      "backbone.blocks.0.mlp.fc2.weight\n",
      "backbone.blocks.0.mlp.fc2.bias\n",
      "backbone.blocks.1.norm1.weight\n",
      "backbone.blocks.1.norm1.bias\n",
      "backbone.blocks.1.attn.qkv.weight\n",
      "backbone.blocks.1.attn.qkv.bias\n",
      "backbone.blocks.1.attn.proj.weight\n",
      "backbone.blocks.1.attn.proj.bias\n",
      "backbone.blocks.1.norm2.weight\n",
      "backbone.blocks.1.norm2.bias\n",
      "backbone.blocks.1.mlp.fc1.weight\n",
      "backbone.blocks.1.mlp.fc1.bias\n",
      "backbone.blocks.1.mlp.fc2.weight\n",
      "backbone.blocks.1.mlp.fc2.bias\n",
      "backbone.blocks.2.norm1.weight\n",
      "backbone.blocks.2.norm1.bias\n",
      "backbone.blocks.2.attn.qkv.weight\n",
      "backbone.blocks.2.attn.qkv.bias\n",
      "backbone.blocks.2.attn.proj.weight\n",
      "backbone.blocks.2.attn.proj.bias\n",
      "backbone.blocks.2.norm2.weight\n",
      "backbone.blocks.2.norm2.bias\n",
      "backbone.blocks.2.mlp.fc1.weight\n",
      "backbone.blocks.2.mlp.fc1.bias\n",
      "backbone.blocks.2.mlp.fc2.weight\n",
      "backbone.blocks.2.mlp.fc2.bias\n",
      "backbone.blocks.3.norm1.weight\n",
      "backbone.blocks.3.norm1.bias\n",
      "backbone.blocks.3.attn.qkv.weight\n",
      "backbone.blocks.3.attn.qkv.bias\n",
      "backbone.blocks.3.attn.proj.weight\n",
      "backbone.blocks.3.attn.proj.bias\n",
      "backbone.blocks.3.norm2.weight\n",
      "backbone.blocks.3.norm2.bias\n",
      "backbone.blocks.3.mlp.fc1.weight\n",
      "backbone.blocks.3.mlp.fc1.bias\n",
      "backbone.blocks.3.mlp.fc2.weight\n",
      "backbone.blocks.3.mlp.fc2.bias\n",
      "backbone.blocks.4.norm1.weight\n",
      "backbone.blocks.4.norm1.bias\n",
      "backbone.blocks.4.attn.qkv.weight\n",
      "backbone.blocks.4.attn.qkv.bias\n",
      "backbone.blocks.4.attn.proj.weight\n",
      "backbone.blocks.4.attn.proj.bias\n",
      "backbone.blocks.4.norm2.weight\n",
      "backbone.blocks.4.norm2.bias\n",
      "backbone.blocks.4.mlp.fc1.weight\n",
      "backbone.blocks.4.mlp.fc1.bias\n",
      "backbone.blocks.4.mlp.fc2.weight\n",
      "backbone.blocks.4.mlp.fc2.bias\n",
      "backbone.blocks.5.norm1.weight\n",
      "backbone.blocks.5.norm1.bias\n",
      "backbone.blocks.5.attn.qkv.weight\n",
      "backbone.blocks.5.attn.qkv.bias\n",
      "backbone.blocks.5.attn.proj.weight\n",
      "backbone.blocks.5.attn.proj.bias\n",
      "backbone.blocks.5.norm2.weight\n",
      "backbone.blocks.5.norm2.bias\n",
      "backbone.blocks.5.mlp.fc1.weight\n",
      "backbone.blocks.5.mlp.fc1.bias\n",
      "backbone.blocks.5.mlp.fc2.weight\n",
      "backbone.blocks.5.mlp.fc2.bias\n",
      "backbone.blocks.6.norm1.weight\n",
      "backbone.blocks.6.norm1.bias\n",
      "backbone.blocks.6.attn.qkv.weight\n",
      "backbone.blocks.6.attn.qkv.bias\n",
      "backbone.blocks.6.attn.proj.weight\n",
      "backbone.blocks.6.attn.proj.bias\n",
      "backbone.blocks.6.norm2.weight\n",
      "backbone.blocks.6.norm2.bias\n",
      "backbone.blocks.6.mlp.fc1.weight\n",
      "backbone.blocks.6.mlp.fc1.bias\n",
      "backbone.blocks.6.mlp.fc2.weight\n",
      "backbone.blocks.6.mlp.fc2.bias\n",
      "backbone.blocks.7.norm1.weight\n",
      "backbone.blocks.7.norm1.bias\n",
      "backbone.blocks.7.attn.qkv.weight\n",
      "backbone.blocks.7.attn.qkv.bias\n",
      "backbone.blocks.7.attn.proj.weight\n",
      "backbone.blocks.7.attn.proj.bias\n",
      "backbone.blocks.7.norm2.weight\n",
      "backbone.blocks.7.norm2.bias\n",
      "backbone.blocks.7.mlp.fc1.weight\n",
      "backbone.blocks.7.mlp.fc1.bias\n",
      "backbone.blocks.7.mlp.fc2.weight\n",
      "backbone.blocks.7.mlp.fc2.bias\n",
      "backbone.blocks.8.norm1.weight\n",
      "backbone.blocks.8.norm1.bias\n",
      "backbone.blocks.8.attn.qkv.weight\n",
      "backbone.blocks.8.attn.qkv.bias\n",
      "backbone.blocks.8.attn.proj.weight\n",
      "backbone.blocks.8.attn.proj.bias\n",
      "backbone.blocks.8.norm2.weight\n",
      "backbone.blocks.8.norm2.bias\n",
      "backbone.blocks.8.mlp.fc1.weight\n",
      "backbone.blocks.8.mlp.fc1.bias\n",
      "backbone.blocks.8.mlp.fc2.weight\n",
      "backbone.blocks.8.mlp.fc2.bias\n",
      "backbone.blocks.9.norm1.weight\n",
      "backbone.blocks.9.norm1.bias\n",
      "backbone.blocks.9.attn.qkv.weight\n",
      "backbone.blocks.9.attn.qkv.bias\n",
      "backbone.blocks.9.attn.proj.weight\n",
      "backbone.blocks.9.attn.proj.bias\n",
      "backbone.blocks.9.norm2.weight\n",
      "backbone.blocks.9.norm2.bias\n",
      "backbone.blocks.9.mlp.fc1.weight\n",
      "backbone.blocks.9.mlp.fc1.bias\n",
      "backbone.blocks.9.mlp.fc2.weight\n",
      "backbone.blocks.9.mlp.fc2.bias\n",
      "backbone.blocks.10.norm1.weight\n",
      "backbone.blocks.10.norm1.bias\n",
      "backbone.blocks.10.attn.qkv.weight\n",
      "backbone.blocks.10.attn.qkv.bias\n",
      "backbone.blocks.10.attn.proj.weight\n",
      "backbone.blocks.10.attn.proj.bias\n",
      "backbone.blocks.10.norm2.weight\n",
      "backbone.blocks.10.norm2.bias\n",
      "backbone.blocks.10.mlp.fc1.weight\n",
      "backbone.blocks.10.mlp.fc1.bias\n",
      "backbone.blocks.10.mlp.fc2.weight\n",
      "backbone.blocks.10.mlp.fc2.bias\n",
      "backbone.blocks.11.norm1.weight\n",
      "backbone.blocks.11.norm1.bias\n",
      "backbone.blocks.11.attn.qkv.weight\n",
      "backbone.blocks.11.attn.qkv.bias\n",
      "backbone.blocks.11.attn.proj.weight\n",
      "backbone.blocks.11.attn.proj.bias\n",
      "backbone.blocks.11.norm2.weight\n",
      "backbone.blocks.11.norm2.bias\n",
      "backbone.blocks.11.mlp.fc1.weight\n",
      "backbone.blocks.11.mlp.fc1.bias\n",
      "backbone.blocks.11.mlp.fc2.weight\n",
      "backbone.blocks.11.mlp.fc2.bias\n",
      "backbone.norm.weight\n",
      "backbone.norm.bias\n",
      "decoder.0.weight\n",
      "decoder.0.bias\n",
      "decoder.1.weight\n",
      "decoder.1.bias\n",
      "decoder.1.running_mean\n",
      "decoder.1.running_var\n",
      "decoder.1.num_batches_tracked\n",
      "decoder.4.weight\n",
      "decoder.4.bias\n",
      "decoder.5.weight\n",
      "decoder.5.bias\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(\"range_vit_segmentation.pth\", map_location=\"cpu\")\n",
    "if isinstance(state_dict, dict) and \"state_dict\" in state_dict:\n",
    "    state_dict = state_dict[\"state_dict\"]\n",
    "\n",
    "def print_keys(d, prefix=\"\"):\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(prefix + str(k))\n",
    "            print_keys(v, prefix + str(k) + \".\")\n",
    "\n",
    "print_keys(state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykitti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
